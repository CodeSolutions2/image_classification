<!DOCTYPE html>
<html>
<head></head>
<body>
	
  <h1 style='text-align: center; margin-bottom: -35px;'>Image labeling webapp</h1>
  <br><br>
	
    <!-- <img id="img" src="https://storage.googleapis.com/images4download0/image2.png" style="display:block" width="224" height="224" /> -->
    <!-- <img id="img" src="apple.png" style="display:block" width="224" height="224" /> -->
    <!-- OR -->
    <!-- Makes a selection file reader from the PC only, not from the cloud -->
    <!-- <input type="file" id="img_input" name="avatar" accept="image/png, image/jpeg"> -->

<!-- Drop down menu: Select image to classify -->
   <label for="select_image">Select an image to classsify/label:</label>
   <select name="select_image_list" id="select_image_list">
        <option value="apple" id="select_this_image">apple</option>
        <option value="tomatoe" id="select_this_image">tomatoe</option>
   </select> 

<!-- <button id="select_image_button" onclick="selectImage()" style="display:block">Select image</button> -->
	
<!-- Select model to classify -->
   <h2 id="select_model" style='text-align: left; display:none'>Select different models to classify the image</h2>
   <div style="width:100%;height:100%;position:absolute;vertical-align:middle;text-align:left;">
        <button id="run_mobilenet_button" onclick="run_mobilenet()" style="display:none">mobilenet</button>&nbsp;&nbsp;&nbsp;<button id="run_edgedetection_classifer_button" onclick="run_edgedetection_classifer()" style="display:none">edgedetection_classifer</button>
    <div>
		
<!-- Once image and model are selected, make image appear in canvas and run model -->
   <div style="width:100%;height:100%;position:absolute;vertical-align:middle;text-align:left;">
        <canvas id="canvasId" width="224" height="224" style="display:none"></canvas>&nbsp;&nbsp;&nbsp;
        <canvas id="canvasId2" width="224" height="224" style="display:none"></canvas>
    <div>

    <div id="output" style="font-family:courier;font-size:24px;height:300px"></div>

    <!-- <textarea id="outData" rows="2" cols="70" placeholder="notification" style="display:block"></textarea> -->


	    
<style>
      canvas {border: 1px solid black;}
    </style>
  
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"> </script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@1.0.0"> </script> 

  
<script>
  // https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/drawImage
  var canvasElement = document.getElementById("canvasId");
  const ctx = canvasElement.getContext("2d");

  var canvasElement2 = document.getElementById("canvasId2");
  const ctx2 = canvasElement2.getContext("2d");
  
  const outp = document.getElementById('output');

  // -------------------------------------------------
	
  // Way 0: eventlistener
  select_this_image.addEventListener("click", () => {
     document.getElementById("select_model").style.display = "block";
     document.getElementById("run_mobilenet_button").style.display = "block";
     document.getElementById("run_edgedetection_classifer_button").style.display = "block";
  });

  // OR

  // Way 1: onclick
  // function selectImage() {
  //    document.getElementById("select_model").style.display = "block";
  //   document.getElementById("run_mobilenet_button").style.display = "block";
  //    document.getElementById("run_edgedetection_classifer_button").style.display = "block";
  // }
	
  // -------------------------------------------------

  function load_image_basedOn_selection() {
	  
	var selected_image = document.getElementById("select_this_image").value;
	  
    	if (selected_image == 'apple') {
          load_image = "apple3D.png";
	} else if (prompt_topic == 'tomatoe') {
          load_image = "tomatoe3D.png";
	} else {
          load_image = "tomatoe3D.png";
	  // load_image = "https://storage.googleapis.com/images4download0/image2.png";
	} 
    return load_image
  }
	
  // -------------------------------------------------
	
  async function run_mobilenet() {

    //document.getElementById("canvasId").style.display = "block";

	  
    try {
      
      const image = new Image();

      image.src = load_image_basedOn_selection();

      image.onload = function (){
        // Draw image on canvas
        ctx.drawImage(image, 0,0);
        // Convert the image element to a tensor using fromPixels
        var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3
        document.getElementById("outData").innerHTML = tf.max(tensor_image);
        const eTensor = tensor_image.expandDims(0); // This is size 1,224,224,3
        // Give image to model
        mobilenet.load().then(model => {model.classify(eTensor).then(predictions => {for(var i = 0; i<predictions.length; i++){outp.innerHTML += "<br/>" + predictions[i].className + " : " + predictions[i].probability;} }); });
      };
    
    } catch (error) {
      document.getElementById("outData").innerHTML = error; 
      // return error
    }
    
  }  // end of run_mobilenet
  
  // -------------------------------------------------

  async function run_edgedetection_classifer(){
 
        // const MODEL_URL = 'https://storage.googleapis.com/tensorflowjsmodels0/model.json';
	const MODEL_URL = 'model.json';
        const model = await tf.loadLayersModel(MODEL_URL);
          
	const image = new Image();

	image.src = load_image_basedOn_selection();
          
          
	image.onload = function (){
		  
            // Draw image on canvas
            //document.getElementById("canvasId").style.display = "block";
            ctx.drawImage(image, 0,0);
		  
            // Convert the image element to a tensor using fromPixels
            var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3
	    
	    const k_rgb_values = tf.tensor4d([[[[ 1000.], [ 1000.], [ 1000.]],[[    0.], [    0.], [    0.]],[[-1000.], [-1000.], [-1000.]]], [[[ 1000.], [ 1000.], [ 1000.]], [[    0.], [    0.], [    0.]], [[-1000.], [-1000.], [-1000.]]], [[[ 1000.], [ 1000.], [ 1000.]], [[    0.], [    0.], [    0.]], [[-1000.], [-1000.], [-1000.]]]], shape=[3, 3, 3, 1], dtype='float32');
		  
            const image_4D = tensor_image.expandDims(0); // This is size 1,224,224,3
	    
            const image_4D_float = tf.cast(image_4D, 'float32')
            const image_filter0 = tf.conv2d(image_4D_float, k_rgb_values, 1, 'same') 

            // Dispose of the intermediate tensors
            tensor_image.dispose();
            k_rgb_values.dispose();
            image_4D.dispose();
            image_4D_float.dispose();
		  
            // Make image values from -1 to 1
            const b = tf.scalar(255);
	    const image_filter = image_filter0.div(b)
	    const shape_out = image_filter.shape;
		  
            document.getElementById("outData").innerHTML = shape_out;
            // 1,276,250,1

            // Dispose of the intermediate tensors
            image_filter0.dispose();
            b.dispose();
		  
            // -----------------------------------------------
            // Draw edge detection image on canvas
            document.getElementById("canvasId2").style.display = "block";
		  
            const edge_image_tensor = tf.reshape(image_filter, [shape_out[1], shape_out[2], shape_out[3]])
		  
	    // Convert the cropped tensor back to an image
            // const edge_image_view = tf.browser.toPixels(edge_image_tensor, document.getElementById('canvasId2'));
		  // OR
		  // Create a new Uint8ClampedArray from the tensor values
   // const data = new Uint8ClampedArray(edge_image_tensor);
		  // Create a new ImageData object with the tensor shape
    //const { width, height } = tensor.shape;
   // const imageData = new ImageData(data, width, height);
		  
         //     ctx2.putImageData(edge_image_view, 0,0);
	    // Uncaught TypeError: CanvasRenderingContext2D.drawImage: Argument 1 could not be converted to any of: HTMLImageElement, SVGImageElement, HTMLCanvasElement, HTMLVideoElement, OffscreenCanvas, ImageBitmap, VideoFrame.
            // -----------------------------------------------
		  
	    // Ensure that tensor is 4d
            const x = tf.reshape(image_filter, [1, shape_out[1], shape_out[2], shape_out[3]])

            const boxes = tf.tensor2d([[0.25, 0.25, 0.75, 0.75]], [1, 4]);
            const boxIndices = tf.tensor1d([0], 'int32');
            const newSize = [512, 512];
            const resizedTensor = tf.image.cropAndResize(x, boxes, boxIndices, newSize);
		  
            document.getElementById("outData").innerHTML = resizedTensor.shape;
		  
            // Give image to model
            const result = model.predict(resizedTensor); 
            outp.innerHTML = result;
		  
          };  // end of image.onload
        //} catch (error) {
        //  document.getElementById("outData").innerHTML = error; 
          // return error
        //}
	  
  }  // end of run_edgedetection_classifer




</script>
</body>
</html>
