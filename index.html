<!DOCTYPE html>
<html>
<head></head>
<body>
  
    <!-- <img id="img" src="https://storage.googleapis.com/images4download0/image2.png" style="display:block" width="224" height="224" /> -->
    <!-- <img id="img" src="apple.png" style="display:block" width="224" height="224" /> -->
    <!-- OR -->
    <!-- Makes a selection file reader from the PC only, not from the cloud -->
    <!-- <input type="file" id="img_input" name="avatar" accept="image/png, image/jpeg"> -->

    <canvas id="canvasId" width="224" height="224" style="display:block"></canvas>
    <canvas id="canvasId2" width="224" height="224" style="display:block"></canvas>
	
    <button id="myBtn" onclick="run_mobilenet()">mobilenet</button>
    <button id="myBtn" onclick="run_edgedetection_classifer()">edgedetection_classifer</button>
  

    <div id="output" style="font-family:courier;font-size:24px;height:300px"></div>

    <textarea id="outData" rows="2" cols="70" placeholder="notification" style="display:block"></textarea>

<style>
      canvas {
        border: 1px solid black;
      }
    </style>
  
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"> </script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@1.0.0"> </script> 

  
<script>
  // https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/drawImage
  var canvasElement = document.getElementById("canvasId");
  const ctx = canvasElement.getContext("2d");

  var canvasElement2 = document.getElementById("canvasId2");
  const ctx2 = canvasElement2.getContext("2d");
  
  const outp = document.getElementById('output');

  // -------------------------------------------------

  async function run_mobilenet() {

    try {
      
      const image = new Image();

      // image.src = "https://storage.googleapis.com/images4download0/image2.png";
      image.src = "apple3D.png";
      // image.src = "tomatoe3D.png";

      image.onload = function (){
        // Draw image on canvas
        ctx.drawImage(image, 0,0);
        // Convert the image element to a tensor using fromPixels
        var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3
        document.getElementById("outData").innerHTML = tf.max(tensor_image);
        const eTensor = tensor_image.expandDims(0); // This is size 1,224,224,3
        // Give image to model
        mobilenet.load().then(model => {model.classify(eTensor).then(predictions => {for(var i = 0; i<predictions.length; i++){outp.innerHTML += "<br/>" + predictions[i].className + " : " + predictions[i].probability;} }); });
      };
    
    } catch (error) {
      document.getElementById("outData").innerHTML = error; 
      // return error
    }
    
  }  // end of run_mobilenet
  
  // -------------------------------------------------


  async function run_edgedetection_classifer(){
        // const MODEL_URL = 'https://storage.googleapis.com/tensorflowjsmodels0/model.json';
	const MODEL_URL = 'model.json';
        const model = await tf.loadLayersModel(MODEL_URL);
    
        //try {
          
          const image = new Image();
    
          // image.src = "https://storage.googleapis.com/images4download0/image2.png";
          //image.src = "apple3D.png";
          image.src = "tomatoe3D.png";
    
          
          
          image.onload = function (){
            // Draw image on canvas
            ctx.drawImage(image, 0,0);
		  
            // Convert the image element to a tensor using fromPixels
            var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3
	    
	    const k_rgb_values = tf.tensor4d([[[[ 1000.], [ 1000.], [ 1000.]],[[    0.], [    0.], [    0.]],[[-1000.], [-1000.], [-1000.]]], [[[ 1000.], [ 1000.], [ 1000.]], [[    0.], [    0.], [    0.]], [[-1000.], [-1000.], [-1000.]]], [[[ 1000.], [ 1000.], [ 1000.]], [[    0.], [    0.], [    0.]], [[-1000.], [-1000.], [-1000.]]]], shape=[3, 3, 3, 1], dtype='float32');
		  
            const image_4D = tensor_image.expandDims(0); // This is size 1,224,224,3
	    
            const image_4D_float = tf.cast(image_4D, 'float32')
            const image_filter0 = tf.conv2d(image_4D_float, k_rgb_values, 1, 'same') 

            // Dispose of the intermediate tensors
            tensor_image.dispose();
            k_rgb_values.dispose();
            image_4D.dispose();
            image_4D_float.dispose();
		  
            // Make image values from -1 to 1
            const b = tf.scalar(255);
	    const image_filter = image_filter0.div(b)
	    const shape_out = image_filter.shape;
		  
            document.getElementById("outData").innerHTML = shape_out;
            // 1,276,250,1

            // Dispose of the intermediate tensors
            image_filter0.dispose();
            b.dispose();
		  
            // -----------------------------------------------
            // Draw edge detection image on canvas
            const edge_image_tensor = tf.reshape(image_filter, [shape_out[1], shape_out[2], shape_out[3]])
		  
	    // Convert the cropped tensor back to an image
            // const edge_image_view = tf.browser.toPixels(edge_image_tensor, document.getElementById('canvasId2'));
		  // OR
		  // Create a new Uint8ClampedArray from the tensor values
   // const data = new Uint8ClampedArray(edge_image_tensor);
		  // Create a new ImageData object with the tensor shape
    //const { width, height } = tensor.shape;
   // const imageData = new ImageData(data, width, height);
		  
         //     ctx2.putImageData(edge_image_view, 0,0);
	    // Uncaught TypeError: CanvasRenderingContext2D.drawImage: Argument 1 could not be converted to any of: HTMLImageElement, SVGImageElement, HTMLCanvasElement, HTMLVideoElement, OffscreenCanvas, ImageBitmap, VideoFrame.
            // -----------------------------------------------
		  
	    // Ensure that tensor is 4d
            const x = tf.reshape(image_filter, [1, shape_out[1], shape_out[2], shape_out[3]])

            const boxes = tf.tensor2d([[0.25, 0.25, 0.75, 0.75]], [1, 4]);
            const boxIndices = tf.tensor1d([0], 'int32');
            const newSize = [512, 512];
            const resizedTensor = tf.image.cropAndResize(x, boxes, boxIndices, newSize);
		  
            document.getElementById("outData").innerHTML = resizedTensor.shape;
		  
            // Give image to model
            const result = model.predict(resizedTensor); 
            outp.innerHTML = result;
		  
          };  // end of image.onload
        //} catch (error) {
        //  document.getElementById("outData").innerHTML = error; 
          // return error
        //}
	  
  }  // end of run_edgedetection_classifer




</script>
</body>
</html>
