<!DOCTYPE html>
<html>
<head></head>
<body>
  
    <!-- <img id="img" src="https://storage.googleapis.com/images4download0/image2.png" style="display:block" width="224" height="224" /> -->
    <!-- <img id="img" src="apple.png" style="display:block" width="224" height="224" /> -->
    <!-- OR -->
    <!-- Makes a selection file reader from the PC only, not from the cloud -->
    <!-- <input type="file" id="img_input" name="avatar" accept="image/png, image/jpeg"> -->

    <canvas id="canvasId" width="224" height="224" style="display:block"></canvas>
    <button id="myBtn" onclick="run_mobilenet()">mobilenet</button>
    <button id="myBtn" onclick="run_edgedetection_classifer()">edgedetection_classifer</button>
  

    <div id="output" style="font-family:courier;font-size:24px;height:300px"></div>

    <textarea id="outData" rows="2" cols="70" placeholder="notification" style="display:block"></textarea>

<style>
      canvas {
        border: 1px solid black;
      }
    </style>
  
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"> </script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@1.0.0"> </script> 

  
<script>
  // https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/drawImage
  var canvasElement = document.getElementById("canvasId");
  const ctx = canvasElement.getContext("2d");
  
  const outp = document.getElementById('output');

  // -------------------------------------------------

  async function run_mobilenet() {

    var IMAGE_SIZE = 224;
    
    // ----------------------

    try {
      
      const image = new Image();

      // image.src = "https://storage.googleapis.com/images4download0/image2.png";
      image.src = "apple3D.png";
      // image.src = "tomatoe.png";

      
      
      image.onload = function (){
        // Draw image on canvas
        ctx.drawImage(image, 0,0);
        // Convert the image element to a tensor using fromPixels
        var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3
        document.getElementById("outData").innerHTML = tf.max(tensor_image);
        const eTensor = tensor_image.expandDims(0); // This is size 1,224,224,3
        // Give image to model
        mobilenet.load().then(model => {model.classify(eTensor).then(predictions => {for(var i = 0; i<predictions.length; i++){outp.innerHTML += "<br/>" + predictions[i].className + " : " + predictions[i].probability;} }); });
      };
    

    } catch (error) {
      document.getElementById("outData").innerHTML = error; 
      // return error
    }
    
  }  // end of run_mobilenet
  
  // -------------------------------------------------


  async function run_edgedetection_classifer(){
        const MODEL_URL = 'http://127.0.0.1:8887/model.json';
        const model = await tf.loadLayersModel(MODEL_URL);
    
        try {
          
          const image = new Image();
    
          // image.src = "https://storage.googleapis.com/images4download0/image2.png";
          image.src = "apple3D.png";
          // image.src = "tomatoe.png";
    
          
          
          image.onload = function (){
            // Draw image on canvas
            ctx.drawImage(image, 0,0);
            // Convert the image element to a tensor using fromPixels
            var tensor_image = tf.browser.fromPixels(image); // This is size 224,224,3
            
            const eTensor = tensor_image.expandDims(0); // This is size 1,224,224,3
            // Give image to model
            const result = model.predict(eTensor); 
            outp.innerHTML = result;
          }; 
        } catch (error) {
          document.getElementById("outData").innerHTML = error; 
          // return error
        }
	  
  }  // end of run_edgedetection_classifer




</script>
</body>
</html>
